<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Bahri Batuhan Bilecen</title>
  <meta name="description" content="Bahri Batuhan Bilecen" />
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <style>
    :root {
      --bg: #ffffff;
      --card: #ffffff;
      --soft: #f3f4f6;
      --text: #111827;
      --muted: #4b5563;
      --accent: #0ea5e9;
      --link: #1d4ed8;
      --shadow: 0 10px 30px rgba(15, 23, 42, 0.08);
      --radius: 18px;

      --c-neurips: #c7d2fe;
      --c-icml: #bfdbfe;
      --c-cvpr: #bae6fd;
      --c-iccv: #a7f3d0;
      --c-eccv: #fecdd3;
      --c-bmvc: #f5d0fe;
      --c-arxiv: #fef3c7;
      --c-chi: #ddd6fe;
      --c-kdd: #bbf7d0;
      --c-default: #e5e7eb;

      --flag-oral: #e03636;
      --flag-workshop: #243955;
    }
    body {
      margin: 0;
      font-family: 'JetBrains Mono', ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      background: radial-gradient(1200px 600px at 80% -10%, #e7f1ff 0%, transparent 60%),
                  radial-gradient(900px 500px at -10% 10%, #fff2e6 0%, transparent 55%),
                  var(--bg);
      color: var(--text);
      line-height: 1.6;
    }
    a { color: var(--link); text-decoration: none; }
    a:hover { text-decoration: underline; }
    .container { max-width: 980px; margin: 0 auto; padding: 28px; }

    .hero { display: grid; grid-template-columns: 140px 1fr; gap: 24px; align-items: start; }
    .avatar { width: 140px; height: 140px; border-radius: 50%; background: var(--soft); box-shadow: var(--shadow); object-fit: cover; }
    h1 { font-size: 36px; margin: 0 0 8px; letter-spacing: -0.02em; }
    .subtitle { color: var(--muted); margin-top: 4px; }

    .links-icons { margin-top: 12px; display: flex; flex-wrap: wrap; gap: 14px; font-size: 20px; }
    .links-icons a { color: var(--text); transition: color 0.2s; }
    .links-icons a:hover { color: var(--accent); }

    .summary { margin-top: 14px; font-size: 15px; color: var(--muted); }

    .section { background: linear-gradient(180deg, rgba(15, 23, 42, 0.02), rgba(15, 23, 42, 0.00)), var(--card); border: 1px solid #e5e7eb; border-radius: var(--radius); padding: 22px; box-shadow: var(--shadow); }

    #pubs { padding-left: 0; list-style: none; }
    .pub { display: grid; grid-template-columns: 286px 1fr; gap: 12px; padding: 14px 0; border-bottom: 1px solid #e5e7eb; align-items: start; }
    .pub:last-child { border-bottom: none; }
    .pub.latest-pub {
      position: relative;
      margin-left: -12px;
      margin-right: -12px;
      padding-left: 12px;
      padding-right: 12px;
      background: linear-gradient(135deg, #e0f2fe, #dbeafe);
      border-radius: 14px;
      box-shadow: inset 0 0 0 1px #7dd3fc, 0 8px 20px rgba(2, 132, 199, 0.12);
    }
    .pub.latest-pub::before {
      content: "Latest";
      position: absolute;
      top: -10px;
      left: 14px;
      font-size: 11px;
      font-weight: 700;
      letter-spacing: 0.04em;
      color: #0c4a6e;
      background: #bae6fd;
      border: 1px solid #38bdf8;
      border-radius: 999px;
      padding: 2px 9px;
    }
    .pub.special-pub {
      position: relative;
      margin-left: -12px;
      margin-right: -12px;
      padding-left: 12px;
      padding-right: 12px;
      background: linear-gradient(135deg, #fff1f2, #fce7f3);
      border-radius: 14px;
      box-shadow: inset 0 0 0 1px #f9a8d4, 0 8px 20px rgba(190, 24, 93, 0.12);
    }
    .pub.special-pub[data-highlight="Spotlight"],
    .pub.special-pub[data-highlight="Challange Winner"] {
      background: linear-gradient(135deg, #fff7ed, #ffedd5);
      box-shadow: inset 0 0 0 1px #fdba74, 0 8px 20px rgba(234, 88, 12, 0.14);
    }
    .pub.special-pub::before {
      content: attr(data-highlight);
      position: absolute;
      top: -10px;
      left: 14px;
      font-size: 11px;
      font-weight: 700;
      letter-spacing: 0.04em;
      color: #9d174d;
      background: #fbcfe8;
      border: 1px solid #f472b6;
      border-radius: 999px;
      padding: 2px 9px;
    }
    .pub.special-pub[data-highlight="Spotlight"]::before,
    .pub.special-pub[data-highlight="Challange Winner"]::before {
      color: #9a3412;
      background: #fed7aa;
      border-color: #fb923c;
    }
    .thumb { width: 280px; height: 160px; border-radius: 12px; overflow: hidden; background: #f8fafc; border: 1px solid #e5e7eb; box-shadow: var(--shadow); }
    .thumb video { width: 100%; height: 100%; object-fit: contain; background: #ffffff; display: block; }
    .thumb img { width: 100%; height: 100%; object-fit: cover; display: block; }
    .thumb-stack { display: flex; flex-direction: column; width: 100%; height: 100%; }
    .thumb-stack video { height: 50%; object-fit: contain; background: #ffffff; }
    .thumb-stack video.thumb-video-top-half {
      object-fit: cover;
      object-position: top center;
    }

    .pub-header { display: flex; align-items: baseline; gap: 10px; flex-wrap: wrap; }
    .pub-title { font-weight: 700; flex-basis: 100%; margin-top: 2px; }

    .badge { font-size: 12px; font-weight: 700; padding: 4px 10px; border-radius: 999px; color: #92400e; background: #fef3c7; border: 1px solid #fcd34d; }
    [data-venue*="chi"] .badge,
    [data-venue*="neurips"] .badge,
    [data-venue*="icml"] .badge,
    [data-venue*="cvpr"] .badge,
    [data-venue*="iccv"] .badge,
    [data-venue*="eccv"] .badge,
    [data-venue*="bmvc"] .badge,
    [data-venue*="kdd"] .badge,
    [data-venue*="arxiv"] .badge { background: #fef3c7; color: #92400e; border-color: #fcd34d; }
    .badge.badge-submission { background: #e5e7eb; color: #374151; border: 1px solid #d1d5db; }

    .flags { display: inline-flex; gap: 6px; align-items: center; }
    .flag { font-size: 12px; font-weight: 700; padding: 4px 10px; border-radius: 999px; border: 1px solid rgba(15, 23, 42, 0.15); display: inline-block; }
    .flag.oral { background: var(--flag-oral); color: #ffffff; }
    .flag.workshop { background: var(--flag-workshop); color: #ffffff; }

    .pub-authors { color: var(--muted); margin-top: 2px; }
    .pub-venue { color: var(--muted); font-style: italic; margin-top: 2px; }
    .pub-links a { margin-right: 12px; }
    

    footer { text-align: center; color: var(--muted); font-size: 14px; margin: 26px 0 60px; }

    @media (max-width: 800px) {
      .hero { grid-template-columns: 1fr; text-align: center; }
      .avatar { margin: 0 auto; }
      .pub { grid-template-columns: 1fr; }
      .thumb { width: 100%; height: 180px; }
    }
  .pub-authors .me { color: #4f46e5; font-weight: 600; } /* indigo accent */
</style>
</head>
<body>
  <main class="container">
    <section class="section">
      <div class="hero">
        <img class="avatar" src="media/avatar.jpg" alt="Portrait of Bahri Batuhan Bilecen" />
        <div>
          <h1>Bahri Batuhan Bilecen</h1>
          <div class="subtitle">PhD student at ETH Z√ºrich</div>
          <div class="links-icons">
            <a href="mailto:bbilecen@ethz.ch" title="Email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=4GUU0H4AAAAJ&hl=tr" target="_blank" title="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
            <a href="https://github.com/three-bee" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/bbatuhan/" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
            <a href="./media/curriculum_vitae.pdf" target="_blank" title="CV"><i class="fa-solid fa-file"></i></a>
          </div>
          <div class="summary">
            <p>
              Hi there üëã I'm a 1st year PhD student at ETH Z√ºrich and Max Planck Institute, under the supervision of 
              <a href="https://inf.ethz.ch/people/person-detail.MjYyNzgw.TGlzdC8zMDQsLTg3NDc3NjI0MQ==.html" target="_blank">Prof. Siyu Tang</a>, 
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele" target="_blank">Prof. Bernt Schiele</a>, 
              and <a href="https://janericlenssen.github.io" target="_blank">Dr. Jan Eric Lenssen</a>, with <a href="https://learning-systems.org" target="_blank">CLS</a> fellowship.
              <p>Now, I focus on generative modeling and representation learning from videos üìΩÔ∏è. Within my 1st year, I had the great chance of collaborating with <a href="https://arvr.google.com" target="_blank">Google XR</a> to push novel video representations forward, under the <a href="https://ethar.ethz.ch" target="_blank">ETHAR</a> project.</p>
            </p>
            <p>
              I got my CS MSc at <a href="https://w3.bilkent.edu.tr/bilkent/" target="_blank">Bilkent University</a> in 2025 with high honors, 
              and EEE BSc at <a href="https://www.metu.edu.tr/" target="_blank">Middle East Technical University (METU)</a> in 2022 with high honors. 
              My MSc thesis focused on 3D reconstruction from single images with generative models, under the supervision of <a href="http://www.cs.bilkent.edu.tr/~adundar/" target="_blank">Prof. Aysegul Dundar</a>, which earned <a href="https://www.linkedin.com/posts/ieeetrcs_thesisawards-tezaemdaeslleri-computersocietyturkiyethesisawards-activity-7378760947798179840-zIdN" target="_blank">the best CS thesis award</a> of 2025 at IEEE CS Turkey branch üöÄ
            </p>
            
            <p>
              I also worked as a full-time research engineer at <a href="https://www.aselsan.com/en" target="_blank">Aselsan Inc.</a> in 2021-2025, where I learned cool signal processing stuff.
            </p>

            <p>
              Besides these I love cats üêà and playing the classical guitar
            </p>
          </div>
        </div>
      </div>
    </section>

    <section class="section" style="margin-top: 22px;">
      <header><h2 style="margin: 0;">üìö Publications</h2></header>
      <ul id="pubs">
<li class="pub latest-pub" data-venue="submission">
      <div class="thumb" data-video-top="https://three-bee.github.io/invact_website/data/phyworld_grids/ours_query_020.mp4" data-video-bottom="https://three-bee.github.io/invact_website/data/paper_vids/grid_2_trim.mp4" data-poster-top="" data-poster-bottom="" data-bottom-view="top-half">
        <img src="https://three-bee.github.io/invact_website/data/arch_27_v2.svg" alt="thumbnail for InvAct: View and Scene-invariant Atomic Action Learning from Videos" style="object-fit: contain; background: #ffffff;">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge badge-submission">In submission</span>
          <span class="pub-title">InvAct: View and Scene-invariant Atomic Action Learning from Videos</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri Batuhan Bilecen,</span> Korrawe Karunratanakul, Vasileios Choutas, Thabo Beeler, Bernt Schiele, Jan Eric Lenssen, Siyu Tang</div>
        <div class="pub-links"><a href="https://three-bee.github.io/invact_website/preprint.pdf" target="_blank">Paper</a> <a href="https://three-bee.github.io/invact_website/" target="_blank">Project</a></div>
      </div>
    </li>
<li class="pub" data-venue="neurips">
      <div class="thumb" data-video="./media/ropecraft.mp4" data-poster=""> <!-- To use a video thumbnail: set data-video="assets/vids/yourclip.mp4" (and optional data-poster). Leave empty to keep image. --> 
        <img src="./media/ropecraft.png" alt="thumbnail for RoPECraft - Training-Free Motion Transfer with Trajectory-Guided Optimization on Diffusion Transformers">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">NeurIPS 2025</span>

          <span class="pub-title">RoPECraft: Training-free Motion Transfer with Trajectory Guided Optimization on DiTs</span>
        </div>
        <div class="pub-authors">Ahmet Berke Gokmen*,  Yigit Ekin*,  <span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span></span>*,  Aysegul Dundar (* joint 1st)</div>
        <!-- <div class="pub-venue">arXiv, 2025.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2505.13344" target="_blank">Paper</a> <a href="https://berkegokmen1.github.io/RoPECraft" target="_blank">Project</a> <a href="https://github.com/berkegokmen1/RoPECraft" target="_blank">Code</a></div>
      </div>
    </li>
<li class="pub" data-venue="iccv">
      <div class="thumb" data-video="./media/iccv25.mp4" data-poster="">
        <img src="./media/head_stylization.png" alt="thumbnail for Identity Preserving 3D Head Stylization with Multiview Score Distillation">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">ICCV 2025</span>

          <span class="pub-title">Identity Preserving 3D Head Stylization with Multiview Score Distillation</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar</div>
        <!-- <div class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2025.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2411.13536" target="_blank">Paper</a> <a href="https://three-bee.github.io/head_stylization" target="_blank">Project</a> <a href="https://github.com/three-bee/3d_head_stylization" target="_blank">Code</a></div>
      </div>
    </li>
<li class="pub special-pub" data-venue="cvpr" data-highlight="Spotlight">
      <div class="thumb" data-video="./media/cvpr25.mp4" data-poster="">
        <img src="./media/triplaneEditing.png" alt="thumbnail for Reference-Based 3D-Aware Image Editing with Triplane">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">CVPR 2025</span>

          <span class="pub-title">Reference-based 3D-aware Image Editing with Triplanes</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Yigit Yalin, Ning Yu, Aysegul Dundar</div>
        <!-- <div class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025.</div> -->
        <div class="pub-links"><a href="https://three-bee.github.io/triplane_edit" target="_blank">Project</a> <a href="https://github.com/three-bee/triplane_edit" target="_blank">Code</a></div>
      </div>
    </li>
<li class="pub" data-venue="neurips">
      <div class="thumb", data-video="./media/nips24.mp4">
        <img src="./media/dual_encoder.png" alt="thumbnail for Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">NeurIPS 2024</span>

          <span class="pub-title">Dual Encoder GAN Inversion for High-fidelity 3D Head Reconstruction from Single Images</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span></span>*,  Ahmet Berke Gokmen*,  Aysegul Dundar (* joint 1st)</div>
        <!-- <div class="pub-venue">Conference on Neural Information Processing Systems (NeurIPS), 2024.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2409.20530" target="_blank">Paper</a> <a href="https://berkegokmen1.github.io/dual-enc-3d-gan-inv/" target="_blank">Project</a> <a href="https://github.com/berkegokmen1/dual-enc-3d-gan-inversion" target="_blank">Code</a></div>
      </div>
    </li>
<li class="pub" data-venue="arxiv">
      <div class="thumb">
        <img src="./media/BCDM_disc.png" alt="thumbnail for Bayesian Conditioned Diffusion Models for Inverse Problems">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge badge-submission">In submission</span>

          <span class="pub-title">Bayesian Conditioned Diffusion Models for Inverse Problems</span>
        </div>
        <div class="pub-authors">Alper Gungor, <span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Tolga Cukur</div>
        <!-- <div class="pub-venue">arXiv, 2024.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2406.09768" target="_blank">Paper</a></div>
      </div>
    </li>
<li class="pub" data-venue="iccv">
      <div class="thumb">
        <img src="./media/inversion-inpainting.jpg" alt="thumbnail for Diverse Inpainting and Editing with GAN Inversion">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">ICCV 2023</span>

          <span class="pub-title">DivInversion: Diverse Inpainting and Editing with GAN Inversion</span>
        </div>
        <div class="pub-authors">Ahmet Burak Yildirim, Hamza Pehlivan, <span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Aysegul Dundar</div>
        <!-- <div class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2023.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2307.15033" target="_blank">Paper</a> <a href="http://divinversion.abyildirim.com" target="_blank">Project</a></div>
      </div>
    </li>
<li class="pub" data-venue="bmvc">
      <div class="thumb">
        <img src="./media/repr_image_SR.png" alt="thumbnail for Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">BMVC 2023</span>

          <span class="pub-title">Towards Clip-free Quantized Super-resolution Networks: How to Tame Representative Images</span>
        </div>
        <div class="pub-authors">Alperen Kalay, <span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Mustafa Ayazoglu</div>
        <!-- <div class="pub-venue">British Machine Vision Conference (BMVC), 2023.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2308.11365" target="_blank">Paper</a></div>
      </div>
    </li>
<li class="pub special-pub" data-venue="cvpr" data-highlight="Challange Winner">
      <div class="thumb">
        <img src="./media/bicubicplusplus.png" alt="thumbnail for Bicubic++ - Designing an Industry-Grade Super-Resolution Network">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">CVPR 2023</span> <span class="flag workshop">Workshop</span>
          <span class="pub-title">Bicubic++: Designing an Industry-Grade Super-Resolution Network</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span></span> and Mustafa Ayazoglu</div>
        <!-- <div class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), NTIRE Workshop, 2023.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2305.02126" target="_blank">Paper</a> <a href="https://github.com/aselsan-research-imaging-team/bicubic-plusplus" target="_blank">Code</a></div>
      </div>
    </li>
<li class="pub" data-venue="eccv">
      <div class="thumb">
        <img src="./media/xcat.png" alt="thumbnail for XCAT - Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">ECCV 2022</span> <span class="flag workshop">Workshop</span>

          <span class="pub-title">XCAT: Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation</span>
        </div>
        <div class="pub-authors">Mustafa Ayazoglu and <span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span></span></div>
        <!-- <div class="pub-venue">European Conference on Computer Vision (ECCV), Advances in Image Manipulation (AIM) Workshop, 2022.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2208.14655" target="_blank">Paper</a></div>
      </div>
    </li>
<li class="pub" data-venue="cvpr">
      <div class="thumb">
        <img src="./media/alignment.png" alt="thumbnail for Efficient Multi-Purpose Cross Attention-Based Image Alignment Block for Edge Devices">
      </div>
      <div>
        <div class="pub-header">
          <span class="badge">CVPR 2022</span> <span class="flag workshop">Workshop</span>

          <span class="pub-title">Efficient Multi-purpose Cross Attention-Based Image Alignment Block for Edge Devices</span>
        </div>
        <div class="pub-authors"><span class="me">Bahri <span class="me">Batuhan</span> <span class="me">Bilecen</span>,</span>  Alparslan Fisne, Mustafa Ayazoglu</div>
        <!-- <div class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Embedded Vision Workshop, 2022.</div> -->
        <div class="pub-links"><a href="https://arxiv.org/abs/2206.00291" target="_blank">Paper</a> </div>
      </div>
    </li>
</ul>
    </section>

    <section class="section" style="margin-top: 22px;">
      <header><h2 style="margin: 0;">üè´ Teaching</h2></header>
      <ul class="list">
        <li>Teaching Assistant, ETH Z√ºrich, 263-5806-00L Digital Humans, 2026</li>
        <li>Teaching Assistant, ETH Z√ºrich, 252-0206-00L Visual Computing, 2025</li>
        <li>Grader, Bilkent University, CS 464 Introduction to Machine Learning, 2024</li>
        <li>Grader, Bilkent University, CS 281 Computers and Data Organization, 2023</li>
      </ul>
    </section>

    <footer>
      <span>¬© <span id="yearNow"></span> Bahri Batuhan Bilecen</span>
    </footer>
  </main>

  <script>
    document.getElementById('yearNow').textContent = new Date().getFullYear();

  function makeThumbVideo(src, poster) {
    const v = document.createElement('video');
    v.src = src;
    v.muted = true;
    v.defaultMuted = true;
    v.autoplay = true;
    v.loop = true;
    v.playsInline = true;
    if (poster) v.setAttribute('poster', poster);
    return v;
  }

  // Turn any .thumb[data-video-top][data-video-bottom] into two stacked autoplay videos.
  document.querySelectorAll('.thumb[data-video-top][data-video-bottom]').forEach(el => {
    const topSrc = el.getAttribute('data-video-top');
    const bottomSrc = el.getAttribute('data-video-bottom');
    if (!topSrc || !bottomSrc) return;

    const topPoster = el.getAttribute('data-poster-top');
    const bottomPoster = el.getAttribute('data-poster-bottom');
    const bottomView = el.getAttribute('data-bottom-view');
    const topVideo = makeThumbVideo(topSrc, topPoster);
    const bottomVideo = makeThumbVideo(bottomSrc, bottomPoster);
    if (bottomView === 'top-half') bottomVideo.classList.add('thumb-video-top-half');

    const stack = document.createElement('div');
    stack.className = 'thumb-stack';
    stack.appendChild(topVideo);
    stack.appendChild(bottomVideo);
    el.innerHTML = '';
    el.appendChild(stack);
  });

  // Turn any .thumb[data-video] into an autoplaying, muted, looping video (with optional poster).
  document.querySelectorAll('.thumb[data-video]').forEach(el => {
    if (el.hasAttribute('data-video-top') && el.hasAttribute('data-video-bottom')) return;
    const src = el.getAttribute('data-video');
    if (!src) return;
    const poster = el.getAttribute('data-poster');
    el.innerHTML = '';
    el.appendChild(makeThumbVideo(src, poster));
  });

  </script>
</body>
</html>
